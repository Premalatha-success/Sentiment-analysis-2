{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "POS tagging using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7afQbd39ARc",
        "colab_type": "text"
      },
      "source": [
        "### Libraries along with their versions used at the time of making notebook-\n",
        "google\t2.0.3\n",
        "\n",
        "nltk\t3.2.5\n",
        "\n",
        "numpy\t1.18.1\n",
        "\n",
        "pandas\t0.25.3\n",
        "\n",
        "tensorflow\t2.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOk8Eu4_t70R",
        "colab_type": "text"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6RZUm0p4wYJ",
        "colab_type": "code",
        "outputId": "a598c97a-63ce-4c39-a1d0-595975c7c506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWi96z-8SyX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OKVkkLaLdPGU"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JK0ZRJoxhrFe"
      },
      "source": [
        "As we are using google colab, we need to mount the google drive to load the data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6RCAcGLd4w",
        "colab_type": "code",
        "outputId": "ce5f2ae6-2bd9-4f17-9ea1-a326cf53775d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8lDTL5oRkmJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT DATA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/NLP/ner_dataset.csv', encoding='latin1')\n",
        "data = data.fillna(method=\"ffill\") # Deal with N/A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZ4pIhxkmJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = list(set(data[\"POS\"].values)) # Read POS values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5dLVpx-kmJS",
        "colab_type": "code",
        "outputId": "bde09fb2-6258-4263-9697-86a80eff2a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "tags # List of possible POS values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RBR',\n",
              " 'RRB',\n",
              " 'VBZ',\n",
              " 'WRB',\n",
              " 'VBD',\n",
              " 'PRP$',\n",
              " 'VBN',\n",
              " 'NN',\n",
              " '$',\n",
              " 'FW',\n",
              " 'RB',\n",
              " 'JJS',\n",
              " 'NNP',\n",
              " 'NNPS',\n",
              " 'NNS',\n",
              " 'VBG',\n",
              " ':',\n",
              " 'RBS',\n",
              " '``',\n",
              " 'WP',\n",
              " 'TO',\n",
              " ';',\n",
              " 'UH',\n",
              " 'VBP',\n",
              " 'MD',\n",
              " 'VB',\n",
              " 'PDT',\n",
              " 'LRB',\n",
              " 'WDT',\n",
              " 'CD',\n",
              " 'IN',\n",
              " 'JJR',\n",
              " 'POS',\n",
              " 'WP$',\n",
              " 'JJ',\n",
              " 'DT',\n",
              " 'EX',\n",
              " 'RP',\n",
              " ',',\n",
              " '.',\n",
              " 'CC',\n",
              " 'PRP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kla7rPZ4kmJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"DUMMY\") # Add a dummy word to pad sentences."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0quKyRPkmJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read sentences\n",
        "\n",
        "class ReadSentences(object): \n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5RMj10qkmJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ReadSentences(data).sentences # Read all sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7CEvxwAkmJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert words and tags into numbers\n",
        "word2id = {w: i for i, w in enumerate(words)}\n",
        "tag2id = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHnxkCxTkmJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare input and output data\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 50\n",
        "X = [[word2id[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(words)-1)\n",
        "y = [[tag2id[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2id[\".\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-R4K9GikmJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert output to one-hot bit\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = [to_categorical(i, num_classes=len(tags)) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAur07mkkmJq",
        "colab_type": "code",
        "outputId": "cc135f05-6e40-4e32-badb-63e1b1c2ad68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNDkmkAkkmJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training and test split by sentences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHFx7nojkmJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc1Ss7aVkmJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input(shape=(max_len,)) # Input layer\n",
        "model = Embedding(input_dim=len(words), output_dim=50, input_length=max_len)(input) # Word embedding layer\n",
        "model = Dropout(0.1)(model) # Dropout\n",
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model) # Bi-directional LSTM layer\n",
        "out = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(model)  # softmax output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDIws8lAkmJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input, out) # Complete model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6oKch0kmJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # Compile with an optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QATrRFNAkmJ8",
        "colab_type": "code",
        "outputId": "3c8fd630-372f-4200-8654-726da39ea2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=3, validation_split=0.1, verbose=1) # Train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 34530 samples, validate on 3837 samples\n",
            "Epoch 1/3\n",
            "34530/34530 [==============================] - 166s 5ms/sample - loss: 0.3817 - accuracy: 0.8964 - val_loss: 0.0707 - val_accuracy: 0.9794\n",
            "Epoch 2/3\n",
            "34530/34530 [==============================] - 161s 5ms/sample - loss: 0.0518 - accuracy: 0.9850 - val_loss: 0.0450 - val_accuracy: 0.9864\n",
            "Epoch 3/3\n",
            "34530/34530 [==============================] - 165s 5ms/sample - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.0380 - val_accuracy: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZI4x1DgkmKA",
        "colab_type": "code",
        "outputId": "5ee87eb8-e73d-4d94-b7ff-4487d6dbe5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "source": [
        "# Demo test on one sample. See how it is mostly correct, but not 100%\n",
        "\n",
        "i = 1213 # Some test sentence sample\n",
        "p = model.predict(np.array([X_te[i]])) # Predict on it\n",
        "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
        "for w, pred in zip(X_te[i], p[0]): # for every word in the sentence\n",
        "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The                  -- DT\n",
            "Gilbert              -- NNP\n",
            "Islands              -- NNP\n",
            "were                 -- VBD\n",
            "granted              -- VBN\n",
            "self-rule            -- NN\n",
            "by                   -- IN\n",
            "the                  -- DT\n",
            "UK                   -- NNP\n",
            "in                   -- IN\n",
            "1971                 -- CD\n",
            "and                  -- CC\n",
            "complete             -- JJ\n",
            "independence         -- NN\n",
            "in                   -- IN\n",
            "1979                 -- CD\n",
            "under                -- IN\n",
            "the                  -- DT\n",
            "new                  -- JJ\n",
            "name                 -- NN\n",
            "of                   -- IN\n",
            "Kiribati             -- NNP\n",
            ".                    -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7FYeWwmqp8u",
        "colab_type": "code",
        "outputId": "71668428-bd97-4545-b4e0-ca042060b2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBTSn305kmKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = nltk.word_tokenize('That was a nice jump')\n",
        "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id[word] for word in sentence]], padding=\"post\", value=len(words)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlLPSYujkmKH",
        "colab_type": "code",
        "outputId": "a4a16f45-3818-43ad-d52a-01bc07f1e3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "source": [
        "p = model.predict(np.array([X_Samp[0]])) # Predict on it\n",
        "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
        "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
        "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "That                 -- DT\n",
            "was                  -- VBD\n",
            "a                    -- DT\n",
            "nice                 -- JJ\n",
            "jump                 -- NN\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n",
            "DUMMY                -- .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVnTDL-HnFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}